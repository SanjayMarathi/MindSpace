{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Anil951/Early-detection-of-mental-health/blob/main/implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jJJdMxxB4Xz",
    "outputId": "a4c0143e-9c92-431d-aeae-43af5782177e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------EARLY DETECTION OF MENTAL HEALTH ISSUES IN ADOLESCENTS SYSTEM------------------------\n",
      "\n",
      "\n",
      "WE ARE DEALING IN 3 STAGES\n",
      "\n",
      "\n",
      "in STAGE-1: All the social media platform data of the user is collected and analysed with our trained model- \n",
      "to get NORMAL/NOT NORMAL in corresponding to MENTAL HEALTH - a score will be assigned\n",
      "\n",
      "in STAGE-2: The use shoudl give us his/her recent exam scores and remarks given by the teachers/mentors - \n",
      "our trained model will evaluate and assign a score\n",
      "\n",
      "in STAGE-3: The use can submit his health record scans \n",
      "\n",
      "\n",
      "------------IN FINAL WE GIVE ANY RECOMMENDATIONS BASED ON OUR RESULTS------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------EARLY DETECTION OF MENTAL HEALTH ISSUES IN ADOLESCENTS SYSTEM------------------------\")\n",
    "\n",
    "print(\"\\n\\nWE ARE DEALING IN 3 STAGES\\n\\n\")\n",
    "\n",
    "print(\"in STAGE-1: All the social media platform data of the user is collected and analysed with our trained model- \")\n",
    "print(\"to get NORMAL/NOT NORMAL in corresponding to MENTAL HEALTH - a score will be assigned\\n\")\n",
    "print(\"in STAGE-2: The use shoudl give us his/her recent exam scores and remarks given by the teachers/mentors - \")\n",
    "print(\"our trained model will evaluate and assign a score\\n\")\n",
    "print(\"in STAGE-3: The use can submit his health record scans \")\n",
    "\n",
    "print(\"\\n\\n------------IN FINAL WE GIVE ANY RECOMMENDATIONS BASED ON OUR RESULTS------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JwOK5f7CAKB"
   },
   "outputs": [],
   "source": [
    "# STAGE 1\n",
    "\n",
    "# COLLECTING USER SOCIAL MEDIA DATA (for prototype purpose we are using REDDIT AND WHATSAPP CHATS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yi6TOPUCEBg"
   },
   "outputs": [],
   "source": [
    "# COLLECTING USER INTERACTION DATA FROM REDDIT (comments the user has done & the hashtags he/she has been using)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8n82ysXuCFh5",
    "outputId": "12a7dd64-ff5e-4669-9d98-79be18f3f7d0"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Reddit username:  cats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments DataFrame:\n",
      "                                              Comment\n",
      "0   https://x.com/donaldjtrumpjr/status/1891992555...\n",
      "1   https://x.com/donaldjtrumpjr/status/1891992555...\n",
      "2   Context: He's talking about social security fr...\n",
      "3                                                Very\n",
      "4   Take it as a $10k lesson and move on.\\n\\nI’d s...\n",
      "5                                                Both\n",
      "6   CRO has two chains actually. Crypto.com chain ...\n",
      "7   [https://leaderboard.bitfinex.com/](https://le...\n",
      "8   Everyone buys shit to sell later at a higher p...\n",
      "9   People love fun. NFTs are fun. End of discussion.\n",
      "10  It will hit 63k, 100k, and eventually 500k. Th...\n",
      "11  How does burning a fee turn a currency into a ...\n",
      "12  Scam. The actual website is lostpoets.xyz.\\n\\n...\n",
      "13                       Nano has no smart contracts.\n",
      "14  You will see old lockers under \"Archives\".\\n\\n...\n",
      "15                                               USDC\n",
      "16  PancakeSwap if you're willing to put liquidity...\n",
      "17  SafeMoon killer is here guys. Invest or get le...\n",
      "18  Better than GhostFace and HODL. Love the auto ...\n",
      "19  Great team. Very active in chat and got big pl...\n",
      "\n",
      "Subreddit Descriptions DataFrame:\n",
      "                                         Description\n",
      "0  Get Richer, Get Smarter with Money.\\n\\nWe’re t...\n",
      "1  r/AskReddit is the place to ask and answer tho...\n",
      "2  The leading community for cryptocurrency news,...\n",
      "3  If you're interested in low market cap cryptoc...\n",
      "4  This is a community run group for DxSale. This...\n"
     ]
    }
   ],
   "source": [
    "# pip install asyncpraw\n",
    "\n",
    "import asyncpraw\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "# Allow nested event loops in Jupyter notebooks (including Google Colab)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Create global variables to store user data and subreddit info\n",
    "data = []\n",
    "subreddits = {}\n",
    "\n",
    "# Create a function to fetch user data asynchronously\n",
    "async def fetch_user_data(username):\n",
    "    async with asyncpraw.Reddit(\n",
    "        client_id='yltdqmhTOrBSlo0P0Ip60Q',  # Replace with your actual Client ID\n",
    "        client_secret='zGk4BrzoApHARnWNbY-vIjy7SgyB3A',  # Replace with your actual client secret\n",
    "        user_agent='MentalHealthAnalyzer/0.1',\n",
    "    ) as reddit:\n",
    "        user = await reddit.redditor(username)\n",
    "\n",
    "        global data, subreddits  # Declare that we are using global variables\n",
    "\n",
    "        user_data = []  # List to hold user comments\n",
    "        subreddit_info = {}  # Dictionary to hold subreddit names and descriptions\n",
    "\n",
    "        # Fetch comments from the user with a limit of 20\n",
    "        async for comment in user.comments.new(limit=20):\n",
    "            subreddit = comment.subreddit\n",
    "            await subreddit.load()  # Load subreddit details to access all attributes\n",
    "\n",
    "            # Add the comment details to user_data\n",
    "            user_data.append(comment.body)  # Store only the comment body\n",
    "\n",
    "            # Store subreddit info if not already stored\n",
    "            if subreddit.display_name not in subreddit_info:\n",
    "                subreddit_info[subreddit.display_name] = subreddit.public_description\n",
    "\n",
    "        # Assign the fetched data to global variables\n",
    "        data = user_data\n",
    "        subreddits = subreddit_info\n",
    "\n",
    "# Create a function to run the async code\n",
    "async def main():\n",
    "    username_input = input(\"Enter Reddit username: \")\n",
    "    await fetch_user_data(username_input)\n",
    "\n",
    "# Run the main function\n",
    "await main()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame for comments\n",
    "reddit_comments_df = pd.DataFrame(data, columns=['Comment'])\n",
    "\n",
    "# Display Comments DataFrame\n",
    "print(\"Comments DataFrame:\")\n",
    "print(reddit_comments_df)\n",
    "\n",
    "# Create a DataFrame for only subreddit descriptions\n",
    "subreddits_df = pd.DataFrame(list(subreddits.values()), columns=['Description'])\n",
    "\n",
    "# Display Subreddits DataFrame\n",
    "print(\"\\nSubreddit Descriptions DataFrame:\")\n",
    "print(subreddits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDpO_UJbCQgu"
   },
   "outputs": [],
   "source": [
    "# COLLECTING USER INTERACTION DATA FROM WHATSAPP (Userchats with most frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alex: Hey… you awake?\n",
      "\n",
      "Jordan: Yeah, can't sleep again. What's up?\n",
      "\n",
      "Alex: Just feeling... off, you know? Everything feels so heavy lately.\n",
      "\n",
      "Jordan: I get it. It’s been the same for me. Every day feels like it's dragging me down, like I’m stuck in quicksand.\n",
      "\n",
      "Alex: Exactly. It’s like I’m surrounded by people, but I feel so alone. I don’t even know who I am anymore.\n",
      "\n",
      "Jordan: That hits hard. Sometimes I wonder what the point of all this is. Like, why keep trying when it feels like nothing ever changes?\n",
      "\n",
      "Alex: Yeah, I keep telling myself it'll get better, but it never does. I’m so tired of pretending everything’s fine when it’s not.\n",
      "\n",
      "Jordan: Same. I put on a happy face for everyone, but inside I feel like I’m falling apart.\n",
      "\n",
      "Alex: I don’t even recognize myself anymore. It’s like the person I used to be is gone, and all that’s left is... this empty shell.\n",
      "\n",
      "Jordan: I know what you mean. I keep trying to fill this void with work, distractions, whatever... but nothing helps. It’s just... there.\n",
      "\n",
      "Alex: I’ve tried talking to people about it, but they don’t understand. They just say, \"Stay positive, things will get better.\" But what if they don’t?\n",
      "\n",
      "Jordan: Yeah, those words don't really help. It’s like people think you can just snap out of it, but they don’t see how deep it goes.\n",
      "\n",
      "Alex: Sometimes I wonder if it’s worth it, you know? Trying so hard just to keep going. I don’t even know why I’m doing it anymore.\n",
      "\n",
      "Jordan: I think about that too. It’s like there’s this darkness I can’t escape from, no matter how much I try.\n",
      "\n",
      "Alex: And the worst part is, I don’t want to burden anyone with how I feel. But keeping it all in is eating me alive.\n",
      "\n",
      "Jordan: You’re not a burden, Alex. I feel the same way. It’s like we’re both drowning, and no one notices.\n",
      "\n",
      "Alex: Yeah... maybe we’re just really good at hiding it.\n",
      "\n",
      "Jordan: I wish I knew how to make it stop. The constant noise in my head... it never shuts up. It’s exhausting.\n",
      "\n",
      "Alex: Me too. It’s like my mind is always racing, reminding me of every failure, every mistake. And I can’t turn it off.\n",
      "\n",
      "Jordan: I get that. It’s like we’re fighting this invisible battle, and no one sees the scars it leaves behind.\n",
      "\n",
      "Alex: I just hope one day, something changes. Because I don’t know how much longer I can keep doing this.\n",
      "\n",
      "Jordan: You’re not alone in this, okay? I’m here, even if we’re both struggling. We’ll figure it out, somehow.\n",
      "\n",
      "Alex: Thanks, Jordan. It helps knowing someone understands. Even if we don’t have all the answers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"./content/chat.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()   # read entire file\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fmbrWkMCRez",
    "outputId": "b6447444-0f17-4208-918d-0caf3c6a6b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the combined DataFrame:\n",
      "                                                 msg\n",
      "0                                    Hey… you awake?\n",
      "1                Yeah, can't sleep again. What's up?\n",
      "2  Just feeling... off, you know? Everything feel...\n",
      "3  I get it. It’s been the same for me. Every day...\n",
      "4  Exactly. It’s like I’m surrounded by people, b...\n",
      "\n",
      "Total number of messages: 43\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of file paths (add each file path here)\n",
    "file_paths = [\n",
    "    \"./content/chat.txt\",\n",
    "    \"./content/chat2.txt\",\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Initialize an empty list to store all messages\n",
    "    all_messages = []\n",
    "\n",
    "    # Loop through each file and process\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            messages = file.readlines()\n",
    "\n",
    "        # Process each message to extract only the content after ': '\n",
    "        for msg in messages:\n",
    "            if ': ' in msg:\n",
    "                content = msg.split(': ', 1)[1].strip()  # Get everything after the first ': '\n",
    "                all_messages.append(content)\n",
    "\n",
    "    # Create a DataFrame from the collected messages\n",
    "    wasap_msg_df = pd.DataFrame(all_messages, columns=['msg'])\n",
    "\n",
    "    print(\"First few rows of the combined DataFrame:\")\n",
    "    print(wasap_msg_df.head())\n",
    "    print(\"\\nTotal number of messages:\", len(wasap_msg_df))\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e.filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urjBYgRaCiOn"
   },
   "outputs": [],
   "source": [
    "# predicting using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UqLfu35hDRLb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ganes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\ganes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\ganes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator MultinomialNB from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\ganes\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model using pickle\n",
    "with open('./content/model_nb.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Define the prediction function\n",
    "def predict_status(sentence):\n",
    "\n",
    "    # Get prediction\n",
    "    prediction = model.predict([sentence])\n",
    "\n",
    "    # Apply threshold and return status\n",
    "    predicted_class = 1 if prediction[0] > 0.5 else 0\n",
    "    return 'NORMAL' if predicted_class == 1 else 'NOT NORMAL'\n",
    "\n",
    "# Apply the prediction function to DataFrames\n",
    "reddit_comments_df['res_status'] = reddit_comments_df['Comment'].apply(predict_status)\n",
    "subreddits_df['res_status'] = subreddits_df['Description'].apply(predict_status)\n",
    "wasap_msg_df['res_status'] = wasap_msg_df['msg'].apply(predict_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "piMDBu7oDJZY"
   },
   "outputs": [],
   "source": [
    "def get_overall_recommendation(dfs_dict):\n",
    "    total_normal = 0\n",
    "    total_not_normal = 0\n",
    "\n",
    "    # ANSI escape codes for colors\n",
    "    RED = \"\\033[91m\"\n",
    "    GREEN = \"\\033[92m\"\n",
    "    RESET = \"\\033[0m\"  # To reset the color back to default\n",
    "\n",
    "    # Calculate totals across all dataframes\n",
    "    for df_name, df in dfs_dict.items():\n",
    "        counts = df['res_status'].value_counts()\n",
    "        total_normal += counts.get('NORMAL', 0)\n",
    "        total_not_normal += counts.get('NOT NORMAL', 0)\n",
    "\n",
    "    # Print the counts with color formatting\n",
    "    print(f\"\\nTotal {GREEN}NORMAL{RESET} messages across all platforms: {GREEN}{total_normal}{RESET}\")\n",
    "    print(f\"Total {RED}NOT NORMAL{RESET} messages across all platforms: {RED}{total_not_normal}{RESET}\")\n",
    "\n",
    "    # Check if the \"NOT NORMAL\" count is 40% or more of the \"NORMAL\" count\n",
    "    if total_normal > 0 and (total_not_normal / total_normal) >= 0.4:\n",
    "        print(f\"\\n{RED}WARNING: The person may be prone to mental health issues (NOT NORMAL messages are 40% or more of NORMAL messages).{RESET}\")\n",
    "\n",
    "    # Make final recommendation based on the total counts\n",
    "    if total_normal > total_not_normal:\n",
    "        print(f\"\\nSTAGE-1 : FINAL ASSESSMENT: {GREEN}No major mental health concerns - normal.{RESET}\")\n",
    "    else:\n",
    "        print(f\"\\nSTAGE-1 : FINAL ASSESSMENT: {RED}Mental health concerns detected - doctor recommended.{RESET}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_aNG-GsDvTy",
    "outputId": "1b09e65c-79e1-4997-dcc9-9b874aaa531d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total \u001b[92mNORMAL\u001b[0m messages across all platforms: \u001b[92m49\u001b[0m\n",
      "Total \u001b[91mNOT NORMAL\u001b[0m messages across all platforms: \u001b[91m19\u001b[0m\n",
      "\n",
      "STAGE-1 : FINAL ASSESSMENT: \u001b[92mNo major mental health concerns - normal.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary of dataframes\n",
    "dfs = {\n",
    "    'Reddit Comments': reddit_comments_df,\n",
    "    'Subreddits': subreddits_df,\n",
    "    'WhatsApp': wasap_msg_df\n",
    "}\n",
    "\n",
    "# Get overall recommendation with the new feature\n",
    "get_overall_recommendation(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNQaGZYD+ZRx5lY6mnSfNKu",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
